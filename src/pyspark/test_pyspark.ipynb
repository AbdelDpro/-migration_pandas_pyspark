{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "22822961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from pyspark.sql.types import BooleanType, DoubleType, StringType\n",
    "from pyspark.sql.functions import udf, col, when, explode, row_number, sum, to_date\n",
    "from pyspark.sql.window import Window\n",
    "from pathlib import Path\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "2130fc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Spark fonctionne\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Test\").getOrCreate()\n",
    "print(\"‚úì Spark fonctionne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "4609f15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration charg√©e\n",
      "{'business_rules': {'exclude_inactive_customers': True,\n",
      "                    'exclude_negative_prices': True,\n",
      "                    'payment_status': 'paid'},\n",
      " 'csv_encoding': 'utf-8',\n",
      " 'csv_float_format': '%.2f',\n",
      " 'csv_sep': ',',\n",
      " 'db_path': './data/sales.db',\n",
      " 'input_dir': './data/march-input',\n",
      " 'input_files': {'customers': 'customers.csv',\n",
      "                 'orders_pattern': 'orders_*.json',\n",
      "                 'refunds': 'refunds.csv'},\n",
      " 'output_columns': ['date',\n",
      "                    'city',\n",
      "                    'channel',\n",
      "                    'orders_count',\n",
      "                    'unique_customers',\n",
      "                    'items_sold',\n",
      "                    'gross_revenue_eur',\n",
      "                    'refunds_eur',\n",
      "                    'net_revenue_eur'],\n",
      " 'output_dir': './data/out'}\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(\"/home/abdeldpro/cours/Esther_brief/migration_pandas_pyspark\")\n",
    "\n",
    "config_file = PROJECT_ROOT / \"settings.yaml\"\n",
    "\n",
    "with config_file.open('r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "print(\"‚úì Configuration charg√©e\")\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "29bd5eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Dossier d'entr√©e : /home/abdeldpro/cours/Esther_brief/migration_pandas_pyspark/data/march-input\n",
      "üìÅ Existe ? True\n",
      "\n",
      "üìÅ Dossier de sortie : /home/abdeldpro/cours/Esther_brief/migration_pandas_pyspark/data/out\n",
      "‚úì Dossier de sortie pr√™t\n"
     ]
    }
   ],
   "source": [
    "# Pr√©parer les chemins\n",
    "input_dir = PROJECT_ROOT / config['input_dir'].lstrip('./')\n",
    "output_dir = PROJECT_ROOT / config['output_dir'].lstrip('./')\n",
    "\n",
    "print(f\"üìÅ Dossier d'entr√©e : {input_dir}\")\n",
    "print(f\"üìÅ Existe ? {input_dir.exists()}\")\n",
    "\n",
    "print(f\"\\nüìÅ Dossier de sortie : {output_dir}\")\n",
    "\n",
    "# Cr√©er le dossier de sortie\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"‚úì Dossier de sortie pr√™t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "c30fb29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Chargement de : customers.csv\n",
      "‚úì 800 clients charg√©s\n",
      "\n",
      "üìã Structure des colonnes :\n",
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- is_active: string (nullable = true)\n",
      "\n",
      "\n",
      "üìÑ Aper√ßu des donn√©es :\n",
      "+-----------+----------+---------+-----------------+--------+---------+\n",
      "|customer_id|first_name|last_name|email            |city    |is_active|\n",
      "+-----------+----------+---------+-----------------+--------+---------+\n",
      "|C0001      |User1     |Test1    |user1@example.com|Nantes  |yes      |\n",
      "|C0002      |User2     |Test2    |user2@example.com|Toulouse|yes      |\n",
      "|C0003      |User3     |Test3    |user3@example.com|Bordeaux|y        |\n",
      "+-----------+----------+---------+-----------------+--------+---------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "# Chemin du fichier customers\n",
    "customers_path = input_dir / config['input_files']['customers']\n",
    "\n",
    "print(f\"üìÑ Chargement de : {customers_path.name}\")\n",
    "\n",
    "# Charger avec Spark\n",
    "df_customers = spark.read.csv(\n",
    "    str(customers_path),\n",
    "    header=True,\n",
    "    sep=config['csv_sep'],\n",
    "    encoding=config['csv_encoding'],\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "print(f\"‚úì {df_customers.count()} clients charg√©s\")\n",
    "print(\"\\nüìã Structure des colonnes :\")\n",
    "df_customers.printSchema()\n",
    "\n",
    "print(\"\\nüìÑ Aper√ßu des donn√©es :\")\n",
    "df_customers.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "efb69a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dir = /home/abdeldpro/cours/Esther_brief/migration_pandas_pyspark/data/march-input\n",
      "Type : <class 'pathlib.PosixPath'>\n",
      "\n",
      "üìÇ Fichiers orders pr√©sents :\n",
      "  - orders_2025-03-08.json\n",
      "  - orders_2025-03-19.json\n",
      "  - orders_2025-03-25.json\n",
      "  - orders_2025-03-18.json\n",
      "  - orders_2025-03-26.json\n",
      "  - orders_2025-03-02.json\n",
      "  - orders_2025-03-01.json\n",
      "  - orders_2025-03-21.json\n",
      "  - orders_2025-03-24.json\n",
      "  - orders_2025-03-20.json\n",
      "  - orders_2025-03-14.json\n",
      "  - orders_2025-03-05.json\n",
      "  - orders_2025-03-06.json\n",
      "  - orders_2025-03-17.json\n",
      "  - orders_2025-03-10.json\n",
      "  - orders_2025-03-04.json\n",
      "  - orders_2025-03-22.json\n",
      "  - orders_2025-03-13.json\n",
      "  - orders_2025-03-15.json\n",
      "  - orders_2025-03-09.json\n",
      "  - orders_2025-03-07.json\n",
      "  - orders_2025-03-31.json\n",
      "  - orders_2025-03-12.json\n",
      "  - orders_2025-03-23.json\n",
      "  - orders_2025-03-16.json\n",
      "  - orders_2025-03-30.json\n",
      "  - orders_2025-03-28.json\n",
      "  - orders_2025-03-27.json\n",
      "  - orders_2025-03-03.json\n",
      "  - orders_2025-03-11.json\n",
      "  - orders_2025-03-29.json\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier ce qu'il y a dans input_dir\n",
    "print(f\"input_dir = {input_dir}\")\n",
    "print(f\"Type : {type(input_dir)}\")\n",
    "\n",
    "# Lister les fichiers orders\n",
    "print(\"\\nüìÇ Fichiers orders pr√©sents :\")\n",
    "for fichier in input_dir.glob(\"orders_*.json\"):\n",
    "    print(f\"  - {fichier.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "a6765094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CONSOLIDATION DE TOUS LES FICHIERS ORDERS DU MOIS\n",
    "# √ânonc√© : \"orders_YYYY-MM-DD.json (commandes et lignes d'articles, un fichier par jour)\"\n",
    "# Boucle sur tous les jours du mois de mars (1 √† 31)\n",
    "# ========================================\n",
    "\n",
    "liste_orders = []\n",
    "\n",
    "for day in range(1, 32): \n",
    "    order_path = os.path.join(input_dir, f\"orders_2025-03-{day:02d}.json\")\n",
    "    if not os.path.exists(order_path):\n",
    "        continue\n",
    "    else:\n",
    "        order = spark.read.json(order_path, multiLine=True)\n",
    "        liste_orders.append(order)\n",
    "\n",
    "if liste_orders:\n",
    "    from functools import reduce\n",
    "    orders = reduce(lambda df1, df2: df1.union(df2), liste_orders)\n",
    "else:\n",
    "    orders = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "43c5122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- channel: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- items: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- qty: long (nullable = true)\n",
      " |    |    |-- sku: string (nullable = true)\n",
      " |    |    |-- unit_price: double (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- payment_status: string (nullable = true)\n",
      "\n",
      "+-------+-------------------+-----------+---------------------------------------------------------+-------------+--------------+\n",
      "|channel|created_at         |customer_id|items                                                    |order_id     |payment_status|\n",
      "+-------+-------------------+-----------+---------------------------------------------------------+-------------+--------------+\n",
      "|app    |2025-03-01 20:36:44|C0793      |[{4, SKU001, 24.9}]                                      |O202503010001|pending       |\n",
      "|web    |2025-03-01 11:30:49|C0676      |[{4, SKU042, -7.5}, {4, SKU042, -7.5}, {5, SKU005, 12.5}]|O202503010001|paid          |\n",
      "|web    |2025-03-01 07:27:00|C0642      |[{1, SKU014, 5.0}]                                       |O202503010003|paid          |\n",
      "|web    |2025-03-01 14:28:46|C0283      |[{2, SKU024, 4.0}]                                       |O202503010004|pending       |\n",
      "|web    |2025-03-01 22:29:42|C0571      |[{1, SKU001, 2.5}]                                       |O202503010005|paid          |\n",
      "+-------+-------------------+-----------+---------------------------------------------------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "Nombre total de commandes consolid√©es : 3193\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier si le DataFrame existe\n",
    "if orders is not None:\n",
    "    orders.printSchema()\n",
    "    orders.show(5, truncate=False)\n",
    "    print(\"Nombre total de commandes consolid√©es :\", orders.count())\n",
    "else:\n",
    "    print(\"Aucun fichier orders trouv√© pour ce mois.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "8ec803cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CHARGEMENT DES REMBOURSEMENTS\n",
    "# √ânonc√© : \"refunds.csv (historique des remboursements)\"\n",
    "# ========================================\n",
    "\n",
    "refunds_path = os.path.join(input_dir, \"refunds.csv\")\n",
    "try:\n",
    "    refunds = spark.read.csv(refunds_path, header=True, inferSchema=True)\n",
    "except AnalysisException:\n",
    "    refunds = None\n",
    "    print(f\"Fichier non trouv√© : {refunds_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "6ecb7c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+------+----------+-------------------+\n",
      "|refund_id|order_id     |amount|reason    |created_at         |\n",
      "+---------+-------------+------+----------+-------------------+\n",
      "|R000001  |O202503010089|error |delay     |2025-03-01 14:03:41|\n",
      "|R000002  |O202503010038|-8.89 |gesture   |2025-03-01 22:16:56|\n",
      "|R000003  |O202503010008|again |item_issue|2025-03-01 20:06:25|\n",
      "|R000004  |O202503010073|-2.47 |coupon    |2025-03-01 20:02:46|\n",
      "|R000005  |O202503010005|-3.83 |gesture   |2025-03-01 09:58:15|\n",
      "+---------+-------------+------+----------+-------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "refunds.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "d5de1a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# FONCTION POUR STANDARDISER LES BOOL√âENS\n",
    "# Les donn√©es peuvent arriver dans diff√©rents formats : \"true\", 1, \"yes\", etc.\n",
    "# Cette fonction les transforme tous en bool√©en Python (True/False)\n",
    "# ========================================\n",
    "\n",
    "def controle_bool(v):\n",
    "    if isinstance(v, bool): return v\n",
    "    if isinstance(v, (int, float)): return bool(v)\n",
    "    if v is None: return False\n",
    "    s = str(v).strip().lower()\n",
    "    return s in (\"1\",\"true\",\"yes\",\"y\",\"t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "035725ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# NETTOYAGE DES DONN√âES CLIENTS\n",
    "# Standardisation du champ is_active et des types de colonnes\n",
    "# ========================================\n",
    "\n",
    "controle_bool_udf = F.udf(controle_bool, BooleanType())\n",
    "\n",
    "customers = (\n",
    "    df_customers\n",
    "        .withColumn(\"is_active\", controle_bool_udf(df_customers[\"is_active\"]))\n",
    "        .withColumn(\"customer_id\", df_customers[\"customer_id\"].cast(StringType()))\n",
    "        .withColumn(\"city\", df_customers[\"city\"].cast(StringType()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "c25e807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# NETTOYAGE DES REMBOURSEMENTS\n",
    "# √ânonc√© : \"Agr√©ger les remboursements par commande, avec des montants n√©gatifs\"\n",
    "# Conversion des montants en num√©rique et gestion des erreurs\n",
    "# ========================================\n",
    "\n",
    "# refunds = (\n",
    "#     refunds\n",
    "#         .withColumn(\n",
    "#             \"amount\",\n",
    "#             when(col(\"amount\").cast(DoubleType()).isNull(), 0.0)\n",
    "#             .otherwise(col(\"amount\").cast(DoubleType()))\n",
    "#         )\n",
    "#         .withColumn(\"created_at\", col(\"created_at\").cast(StringType()))\n",
    "# )\n",
    "\n",
    "\n",
    "refunds_clean = (\n",
    "        refunds.withColumn(\"amount\", F.expr(\"try_cast(amount AS double)\"))\n",
    "        .na.fill({\"amount\": 0.0})\n",
    "        .select(\"order_id\", \"amount\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "62ecbcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|order_id     |amount|\n",
      "+-------------+------+\n",
      "|O202503010089|0.0   |\n",
      "|O202503010038|-8.89 |\n",
      "|O202503010008|0.0   |\n",
      "|O202503010073|-2.47 |\n",
      "|O202503010005|-3.83 |\n",
      "+-------------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "refunds_clean.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "94ad2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# FILTRAGE DES COMMANDES PAY√âES\n",
    "# √ânonc√© : \"Conserver uniquement les commandes pay√©es (payment_status = 'paid')\"\n",
    "# ========================================\n",
    "\n",
    "ln_initial = orders.count()\n",
    "orders = orders.filter(col(\"payment_status\") == \"paid\")\n",
    "ln_final = orders.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "96260e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- items: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- qty: long (nullable = true)\n",
      " |    |    |-- sku: string (nullable = true)\n",
      " |    |    |-- unit_price: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- col: struct (nullable = true)\n",
      " |    |-- qty: long (nullable = true)\n",
      " |    |-- sku: string (nullable = true)\n",
      " |    |-- unit_price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Etude de la structure avant explode\n",
    "orders.select(\"items\").printSchema()\n",
    "orders.select(explode(\"items\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "37828d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# EXPLOSION DES LIGNES D'ARTICLES\n",
    "# Chaque commande contient plusieurs articles (dans une liste \"items\")\n",
    "# On \"√©clate\" cette liste pour avoir une ligne par article\n",
    "# ========================================\n",
    "\n",
    "orders2 = orders.withColumn(\"item\", explode(col(\"items\")))\n",
    "orders2 = orders2.select(\n",
    "    *[col(c) for c in orders2.columns if c != \"items\"],\n",
    "    col(\"item.qty\").alias(\"item_qty\"),\n",
    "    col(\"item.sku\").alias(\"item_sku\"),\n",
    "    col(\"item.unit_price\").alias(\"item_unit_price\")\n",
    ").drop(\"items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "a2cf6798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------+-------------+--------------+--------+--------+---------------+\n",
      "|channel|created_at         |customer_id|order_id     |payment_status|item_qty|item_sku|item_unit_price|\n",
      "+-------+-------------------+-----------+-------------+--------------+--------+--------+---------------+\n",
      "|web    |2025-03-01 11:30:49|C0676      |O202503010001|paid          |5       |SKU005  |12.5           |\n",
      "|web    |2025-03-01 07:27:00|C0642      |O202503010003|paid          |1       |SKU014  |5.0            |\n",
      "|web    |2025-03-01 22:29:42|C0571      |O202503010005|paid          |1       |SKU001  |2.5            |\n",
      "|web    |2025-03-01 09:24:19|C0704      |O202503010006|paid          |1       |SKU039  |9.9            |\n",
      "|web    |2025-03-01 09:24:19|C0704      |O202503010006|paid          |4       |SKU037  |15.0           |\n",
      "+-------+-------------------+-----------+-------------+--------------+--------+--------+---------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# REJET DES ARTICLES √Ä PRIX N√âGATIF\n",
    "# √ânonc√© : \"√âcarter toute ligne d'article avec prix unitaire n√©gatif (et consigner ces rejets)\"\n",
    "# ========================================\n",
    "\n",
    "orders2 = orders2.drop(\"item\")\n",
    "\n",
    "neg_items = orders2.filter(col(\"item_unit_price\") < 0)\n",
    "n_neg = neg_items.count()\n",
    "if n_neg > 0:\n",
    "    rejects_path = os.path.join(output_dir, \"rejects_items.csv\")\n",
    "\n",
    "    neg_items.coalesce(1).write.mode(\"overwrite\").csv(\n",
    "        rejects_path, \n",
    "        header=True,\n",
    "        encoding=enc\n",
    "    )\n",
    "orders2 = orders2.filter(col(\"item_unit_price\") >= 0)\n",
    "\n",
    "orders2.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "4f1e33fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D√©doublonnage : 4385 commandes supprim√©es\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# D√âDUPLICATION DES COMMANDES\n",
    "# √ânonc√© : \"D√©dupliquer sur order_id (garder la premi√®re occurrence)\"\n",
    "# On trie par date de cr√©ation et on garde la premi√®re occurrence par order_id\n",
    "# ========================================\n",
    "\n",
    "before = orders2.count()\n",
    "window = Window.partitionBy(\"order_id\").orderBy(\"created_at\")\n",
    "orders3 = orders2.withColumn(\"row_num\", row_number().over(window))\n",
    "orders3 = orders3.filter(col(\"row_num\") == 1)\n",
    "orders3 = orders3.drop(\"row_num\")\n",
    "after = orders3.count()\n",
    "\n",
    "print(f\"D√©doublonnage : {before - after} commandes supprim√©es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "34f25c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------+-------------------+----------+-----------------+\n",
      "|order_id     |customer_id|channel|created_at         |items_sold|gross_revenue_eur|\n",
      "+-------------+-----------+-------+-------------------+----------+-----------------+\n",
      "|O202503010001|C0676      |web    |2025-03-01 11:30:49|5         |62.5             |\n",
      "|O202503010003|C0642      |web    |2025-03-01 07:27:00|1         |5.0              |\n",
      "|O202503010005|C0571      |web    |2025-03-01 22:29:42|1         |2.5              |\n",
      "|O202503010006|C0704      |web    |2025-03-01 09:24:19|1         |9.9              |\n",
      "|O202503010007|C0464      |app    |2025-03-01 15:50:48|1         |24.9             |\n",
      "+-------------+-----------+-------+-------------------+----------+-----------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CALCUL DU REVENU BRUT PAR COMMANDE\n",
    "# Calcul : quantit√© √ó prix unitaire, puis agr√©gation par commande\n",
    "# ========================================\n",
    "\n",
    "orders3 = orders3.withColumn(\n",
    "    \"line_gross\", \n",
    "    col(\"item_qty\") * col(\"item_unit_price\")\n",
    ")\n",
    "\n",
    "per_order = orders3.groupBy(\n",
    "    \"order_id\", \n",
    "    \"customer_id\", \n",
    "    \"channel\", \n",
    "    \"created_at\"\n",
    ").agg(\n",
    "    sum(\"item_qty\").alias(\"items_sold\"),\n",
    "    sum(\"line_gross\").alias(\"gross_revenue_eur\")\n",
    ")\n",
    "\n",
    "per_order.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "2b3d4f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients inactifs exclus : 340\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# EXCLUSION DES CLIENTS INACTIFS\n",
    "# √ânonc√© : \"Exclure les clients inactifs (is_active = false)\"\n",
    "# On fait une jointure avec la table customers et on filtre sur is_active = True\n",
    "# ========================================\n",
    "\n",
    "len_init = per_order.count()\n",
    "per_order = per_order.join(\n",
    "    customers.select(\"customer_id\", \"city\", \"is_active\"),\n",
    "    on=\"customer_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "per_order = per_order.filter(col(\"is_active\") == True)\n",
    "len_after = per_order.count()\n",
    "\n",
    "print(f\"Clients inactifs exclus : {len_init - len_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "a04ff0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateType()"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================================\n",
    "# STANDARDISATION DES DATES\n",
    "# Conversion de diff√©rents formats de date en format ISO (YYYY-MM-DD)\n",
    "# ========================================\n",
    "\n",
    "per_order = per_order.withColumn(\n",
    "    \"order_date\",\n",
    "    to_date(col(\"created_at\"))\n",
    ")\n",
    "\n",
    "per_order.schema[\"order_date\"].dataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "5a65d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# AGR√âGATION DES REMBOURSEMENTS PAR COMMANDE\n",
    "# √ânonc√© : \"Agr√©ger les remboursements par commande, avec des montants n√©gatifs\"\n",
    "# ========================================\n",
    "\n",
    "# S√©curisation des montants de remboursement + agr√©gation\n",
    "refunds_sum = (\n",
    "    refunds\n",
    "        .withColumn(\n",
    "            \"amount\",\n",
    "            F.expr(\"try_cast(amount AS double)\")   # -> renvoie null si 'error'\n",
    "        )\n",
    "        .fillna({\"amount\": 0.0})                  # invariant : amount doit √™tre num√©rique\n",
    "        .groupBy(\"order_id\")\n",
    "        .agg(F.sum(\"amount\").alias(\"refunds_eur\"))\n",
    ")\n",
    "\n",
    "per_order = (\n",
    "    per_order\n",
    "        .join(refunds_sum, on=\"order_id\", how=\"left\")\n",
    "        .fillna({\"refunds_eur\": 0.0})\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "id": "7d5c1bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-------+-------------------+----------+------------------+---------+---------+----------+-------------------+\n",
      "|     order_id|customer_id|channel|         created_at|items_sold| gross_revenue_eur|     city|is_active|order_date|        refunds_eur|\n",
      "+-------------+-----------+-------+-------------------+----------+------------------+---------+---------+----------+-------------------+\n",
      "|O202503010001|      C0676|    web|2025-03-01 11:30:49|         5|              62.5|Marseille|     true|2025-03-01|                0.0|\n",
      "|O202503010003|      C0642|    web|2025-03-01 07:27:00|         1|               5.0| Toulouse|     true|2025-03-01|              -3.13|\n",
      "|O202503010005|      C0571|    web|2025-03-01 22:29:42|         1|               2.5| Toulouse|     true|2025-03-01|             -35.42|\n",
      "|O202503010007|      C0464|    app|2025-03-01 15:50:48|         1|              24.9|   Nantes|     true|2025-03-01|                0.0|\n",
      "|O202503010008|      C0317|    app|2025-03-01 20:56:15|         2|              30.0|Marseille|     true|2025-03-01|              -3.69|\n",
      "|O202503010009|      C0561|    app|2025-03-01 22:22:34|         2|              16.0|     Lyon|     true|2025-03-01|                0.0|\n",
      "|O202503010010|      C0364|    app|2025-03-01 09:14:25|         5|             124.5|    Lille|     true|2025-03-01|                0.0|\n",
      "|O202503010011|      C0368|    web|2025-03-01 19:49:33|         3|              12.0|    Paris|     true|2025-03-01|                0.0|\n",
      "|O202503010012|      C0475|    web|2025-03-01 09:09:20|         5|             124.5|    Paris|     true|2025-03-01|                0.0|\n",
      "|O202503010015|      C0228|    web|2025-03-01 12:02:16|         3|59.699999999999996|    Paris|     true|2025-03-01|              -6.76|\n",
      "|O202503010016|      C0663|    app|2025-03-01 22:03:06|         3| 74.69999999999999| Bordeaux|     true|2025-03-01|                0.0|\n",
      "|O202503010017|      C0777|    app|2025-03-01 10:30:20|         3|              45.0|     Nice|     true|2025-03-01|                0.0|\n",
      "|O202503010018|      C0383|    app|2025-03-01 11:49:28|         1|              15.0|Marseille|     true|2025-03-01|              -3.65|\n",
      "|O202503010019|      C0331|    app|2025-03-01 14:30:07|         2|               5.0|Marseille|     true|2025-03-01|                0.0|\n",
      "|O202503010020|      C0153|    web|2025-03-01 15:26:26|         5|              40.0| Toulouse|     true|2025-03-01|                0.0|\n",
      "|O202503010021|      C0172|    app|2025-03-01 15:31:06|         2|              39.8| Bordeaux|     true|2025-03-01|-25.549999999999997|\n",
      "|O202503010022|      C0244|    web|2025-03-01 10:24:18|         3|              15.0| Bordeaux|     true|2025-03-01|                0.0|\n",
      "|O202503010023|      C0017|    web|2025-03-01 21:51:32|         5|              40.0|    Paris|     true|2025-03-01|                0.0|\n",
      "|O202503010025|      C0739|    app|2025-03-01 08:33:51|         4|              16.0|Marseille|     true|2025-03-01|               -2.6|\n",
      "|O202503010028|      C0172|    web|2025-03-01 10:19:16|         2|              16.0| Bordeaux|     true|2025-03-01|                0.0|\n",
      "+-------------+-----------+-------+-------------------+----------+------------------+---------+---------+----------+-------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "per_order.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "509dac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers la base SQLite\n",
    "import sqlite3\n",
    "\n",
    "db_path = \"sales.db\"  # ou \"data/sales.db\" si tu veux un sous-dossier\n",
    "\n",
    "# S√©lection des colonnes PySpark\n",
    "per_order_save = per_order.select(\n",
    "    \"order_id\", \"customer_id\", \"city\", \"channel\",\n",
    "    \"order_date\", \"items_sold\", \"gross_revenue_eur\"\n",
    ")\n",
    "\n",
    "# Conversion en Pandas\n",
    "per_order_pd = per_order_save.toPandas()\n",
    "\n",
    "# Sauvegarde dans SQLite\n",
    "conn = sqlite3.connect(db_path)\n",
    "per_order_pd.to_sql(\"orders_clean\", conn, if_exists=\"replace\", index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "95d0f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SAUVEGARDE DANS SQLITE : TABLE orders_clean\n",
    "# √ânonc√© : \"Une base SQLite sales.db comprenant : orders_clean (d√©tails nettoy√©s par commande)\"\n",
    "# ========================================\n",
    "\n",
    "# import sqlite3\n",
    "\n",
    "# # On s√©lectionne les colonnes comme en Pandas\n",
    "# per_order_save = per_order.select(\n",
    "#     \"order_id\", \"customer_id\", \"channel\", \"created_at\", \n",
    "#     \"items_sold\", \"gross_revenue_eur\", \"city\", \"is_active\", \"order_date\", \"refunds_eur\"\n",
    "# )\n",
    "\n",
    "# # Conversion en Pandas\n",
    "# per_order_pd = per_order_save.toPandas()\n",
    "\n",
    "# # Connexion SQLite\n",
    "# conn = sqlite3.connect(db_path)\n",
    "# per_order_pd.to_sql(\"orders_clean\", conn, if_exists=\"replace\", index=False)\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d15ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
